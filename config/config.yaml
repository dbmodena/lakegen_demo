model_list:
  - model_name: llama-3.1-8b-instant # Model Alias to use for requests
    litellm_params:
      model: groq/llama-3.1-8b-instant
      api_key: "os.environ/GROQ_API_KEY" # API Key for the model
  - model_name: llama-3.3-70b-versatile # Model Alias to use for requests
    litellm_params:
      model: groq/llama-3.3-70b-versatile
      api_key: "os.environ/GROQ_API_KEY" # API Key for the model
  - model_name: qwen-qwq-32b # Model Alias to use for requests
    litellm_params:
      model: groq/qwen-qwq-32b
      api_key: "os.environ/GROQ_API_KEY" # API Key for the model
  - model_name: mistral-saba-24b # Model Alias to use for requests
    litellm_params:
      model: groq/mistral-saba-24b
      api_key: "os.environ/GROQ_API_KEY" # API Key for the model
  - model_name: mistral-saba-24b # Model Alias to use for requests
    litellm_params:
      model: groq/mistral-saba-24b
      api_key: "os.environ/GROQ_API_KEY" # API Key for the model
  - model_name: qwen-2.5-32b # Model Alias to use for requests
    litellm_params:
      model: groq/qwen-2.5-32b
      api_key: "os.environ/GROQ_API_KEY" # API Key for the model
  - model_name: deepseek-r1-distill-llama-70b-specdec # Model Alias to use for requests
    litellm_params:
      model: groq/deepseek-r1-distill-llama-70b-specdec
      api_key: "os.environ/GROQ_API_KEY" # API Key for the model
  - model_name: deepseek-r1-distill-llama-70b-specdec # Model Alias to use for requests
    litellm_params:
      model: groq/deepseek-r1-distill-llama-70b-specdec
      api_key: "os.environ/GROQ_API_KEY" # API Key for the model
  - model_name: ollama-qwen2.5-14b # Model Alias to use for requests
    litellm_params:
      model: ollama/qwen2.5:14b
      api_base: "http://localhost:11434"
      stream: true
  - model_name: ollama-gemma3 # Model Alias to use for requests
    litellm_params:
      model: ollama/gemma3:12b-it-q8_0
      api_base: "http://localhost:11434"
      stream: true